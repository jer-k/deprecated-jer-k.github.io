---
published: false
---
Given all that, let’s talk about VIPR, which stands for Vehicle Intelligence Project Resource. My guess is that the name came from a desire to be a car, but sometimes the acronym isn’t perfect, but the repo was created before I joined the project. We’re going to cover a lot of ground very quickly.


As we set out to build VIPR the primary objective was to get away from a process that took multiple days and build an application that could load and publish data every day. Because this is the core of the application, we’re going to take some time to look at how we accomplish our data ingestion process and how that builds the foundation of which all the other data sets rely on before covering some, but not all, of the other functionality of the application and where you can find that data on our website today.

Data Ingestion Process
Data Editing UI
Features UI
Images UI
Comparables UI
Publish UI

# VIPR Data Ingestion Process
A foreword that this section is going to be the only section that contains code references and is a deep dive into the behind the scenes process.
At the core of VIPR is a daily ingestion process of Chrome data. They provide us with CSV files that have their own schema, but we only take parts of that schema and transform it into our own. For each file we have a loader class which defines the schema from the file, along with other meta data points and functions that can run after we insert rows into table. Here is an example loader

```ruby
raw_table_name 'makes'
raw_key 'makeId'
raw_schema(
  'makeId' => 'integer',
  'manufacturerId' => 'integer',
  'makeName' => 'varchar(50)'
)

file_name 'Makes'
model Make
key :external_make_id

mappings(
  external_make_id: 'makeId',
  name: 'makeName'
)

associations(
  Manufacturer => { external_manufacturer_id: 'manufacturerId' }
)

before_load do
end

after_load do
end

before_create do |make, row|
end

after_create do |make_attrs, raw_row|
end
```

We’ll cover each piece briefly. 
`raw_table_name` simply defines the name of the table on our raw PostgresSQL schema. 
`raw_key` indicates the primary key of that table
`raw_schema` is the schema definition of the table
`file_name` tells the loader which file to read the data from and model is accompanying ActiveRecord based class. 
`mappings` indicate how we’re mapping the data from the raw table to the ActiveRecord based table
`associations` tells us how to find the associated classes based on its own mapping.
`before_load` runs before the loads starts doing any processing
`after_load` is the final block the loader will run
`before_create` allows for preprocessing of any row before it goes into the database
`after_create` allows for postprocessing

Now that we have an idea about how we’re translating the data, lets quickly dive into how we load the data every day. First lets take a look at a report that is generated if we were to initialize our local environment with the full data set.

```ruby
Slurping raw files into `raw_schema_20190530170648`
00:00:01 | Manufacturers            |      1.0s taken           810 records slurped     772.7 records/sec
00:00:01 | Divisions                |      0.8s taken         1,014 records slurped
00:00:02 | Models                   |      0.9s taken         8,040 records slurped
00:00:03 | CategoryHeaders          |      1.0s taken           792 records slurped     772.9 records/sec
00:00:04 | Categories               |      0.8s taken         5,861 records slurped
00:00:05 | StandardHeaders          |      0.7s taken           189 records slurped
00:00:06 | TechTitleHeaders         |      1.1s taken           528 records slurped     482.4 records/sec
00:00:07 | TechTitles               |      1.0s taken         6,852 records slurped    6723.2 records/sec
00:00:08 | Styles                   |      1.2s taken        65,609 records slurped   55652.5 records/sec
00:00:14 | VinPatterns              |      5.8s taken       283,424 records slurped   48586.4 records/sec
00:01:24 | Standards                |     69.9s taken     5,109,844 records slurped   73063.2 records/sec
00:02:22 | TechSpecs                |     58.4s taken     8,140,581 records slurped  139387.2 records/sec
00:03:18 | Options                  |     55.6s taken     3,191,725 records slurped   57408.6 records/sec
00:03:41 | OrderRules               |     22.9s taken     3,054,255 records slurped  133460.3 records/sec
00:04:04 | Prices                   |     22.9s taken     3,280,782 records slurped  143130.2 records/sec
00:07:16 | Colors                   |    191.8s taken     3,381,339 records slurped   17628.0 records/sec

Importing raw tables into VIPR schema
00:11:16 | Manufacturers            |      1.1s taken            41 records      36.9 records/sec
00:11:18 | Divisions                |      1.1s taken            62 records      56.4 records/sec
00:14:32 | Models                   |    194.2s taken         8,040 records      41.4 records/sec
00:14:32 | CategoryHeaders          |      0.1s taken            33 records
00:14:32 | Categories               |      0.1s taken           245 records
00:14:32 | StandardHeaders          |      0.0s taken            14 records
00:14:32 | TechTitleHeaders         |      0.0s taken            22 records
00:14:32 | TechTitles               |      0.2s taken           290 records
01:00:40 | Styles                   |   2768.1s taken        65,609 records      23.7 records/sec
01:51:15 | VinPatterns              |   3034.5s taken       225,832 records      74.4 records/sec
02:12:11 | Standards                |   1256.4s taken     9,469,241 records    7536.7 records/sec
02:42:30 | TechSpecs                |   1818.4s taken     8,066,938 records    4436.3 records/sec
03:05:33 | Options                  |   1383.9s taken     7,341,909 records    5305.2 records/sec
03:18:16 | OrderRules               |    762.8s taken     2,925,422 records    3835.1 records/sec
03:34:27 | Prices                   |    970.4s taken     3,280,782 records    3380.8 records/sec
04:06:02 | Colors                   |   1895.7s taken     1,576,469 records     831.6 records/sec
```

As you can see that’s roughly XX million rows that had to be inserted (XX raw rows and YY vipr rows), along with extra processing from tracking and creating all the associations and executing all the callback functions. I’m hand waving over the full code that actually runs the entire process, but it’s a Ruby class that batches up the data to insert and tracks what is inserted via a class level cache so we can build the associations. Instead we’ll cover parts of the process in pseudo code and link to some real code on Github. To do heavy inserting, we rely on PostgreSQL COPY. If you aren’t familiar with COPY, it is described as

Here’s how we would go about initially loading the data
Create a new PostgresSQL schema raw_data_<timestamp>
Loop through each loader class creating a table in the raw_data schema
Insert the raw data from the csv files into the raw tables via our copy_from_file function
Loop through each loader class again, taking the raw data in batches using a CURSOR and executing the callback methods while building up the id cache using insert_with_copy.


Now we have a database that has been initialized on a given day (recall the schema we created raw_data_<timestamp>). However, vehicle data is an ever moving dataset and not only are we getting new vehicles, but we’re also receiving updates about previous vehicles. We needed to build upon our initial loading process to determine what updates occur each day. Let’s take a look at the output of what our daily loading process looks like.

Each day we build another new schema, raw_data_<timestamp> and repeat the steps of loading data into the raw tables. This time, instead of looping through the loaders again and mapping the data into our schema, we run a query that returns a diff between today’s raw tables () and yesterday’s raw tables (). The diffs create three types ‘changes’: ‘create’, ‘update’, and ‘destroy’. A ‘create’ change surfaces when we find a value for the `raw_key` attribute in today’s schema that isn’t there in yesterday. The opposite is true for a destroy, where in a `raw_key` is not present in today’s table, but was there yesterday. Finally an `update` change is created when the `raw_key` is present in both tables and we notice that the value of one or more columns has changed. The result of the query is looped through and turned into Ruby hash’s and then inserted into the database again via `insert_with_copy`. This process runs every night so that the changes ready to be reviewed by the data team in the morning.

Here is an example of a ‘create’ change returned from the database.

That team is able to accept the changes, which in the case of our create example above, would create a new record on the styles table or reject them, if say an ‘update’ change seems to change a value to something incorrect. 


# Data Editing UI
If you recall from the first section, we covered the topic of having to repeat manual entry of data into CSV’s each week during the Configurator process. In VIPR, which all the data always residing in the database, there is no longer any repeat work. Once a data team member adds or edits data, it gets stored in the database and hopefully never has be modified again. Let’s take a look at the one of the main UI’s for this data editing.

Whoops, I think we ended up rebuilding Excel in a web app… but in the end editing the data in Excel is what many of the data team members felt comfortable with. Not all functionality of Excel is present, but let’s run through a few things we can do.

Add multiple columns of data

Reorganize the columns

Add changes and see highlights of what has actually changed

Apply changes across multiple columns

Finally, we can save the changes to the database.

# Generic Features UI
Another goal that arose during the time we were building VIPR was to have the ability to create generic features. What I mean by that is if you look at BMW 3 Series and you want to add <> it is called <>, but if you look at this Merdecez-Benz C Class it is called <>. The problem this creates is when a car buyer wants to cross shop these vehicles, without knowing this exact nomenclature defined by the OEM’s, it is hard to understand if both vehicles have <>. This is our where VIPR comes in. We 
